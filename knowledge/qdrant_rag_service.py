"""
Qdrant RAG Service for Query Answering
Provides semantic search using Qdrant vector database for product queries.

Flow:
.NET â†’ gá»­i data + question â†’ Python â†’ embed data vÃ o Qdrant â†’ query Qdrant â†’ LLM format â†’ tráº£ vá»
"""
import os
import json
import hashlib
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta

from qdrant_client import QdrantClient
from qdrant_client.http import models
from qdrant_client.http.models import (
    Distance, VectorParams, PointStruct,
    Filter, FieldCondition, MatchValue
)

import google.generativeai as genai

logger = logging.getLogger(__name__)

# Constants
EMBEDDING_MODEL = "models/text-embedding-004"  # Google's embedding model
EMBEDDING_DIMENSION = 768
COLLECTION_PREFIX = "crawl_rag_"
TOP_K_RESULTS = 500  # Max number of results to retrieve (increased for large datasets)


class QdrantRAGService:
    """
    RAG service using Qdrant for semantic search on product data.
    
    Flow:
    1. Receive context data (JSON products) from .NET
    2. Parse products and create text representations
    3. Embed each product using Google's embedding model
    4. Store in Qdrant collection (temporary, per session)
    5. Query using semantic search
    6. Return relevant products for LLM to answer
    """
    
    def __init__(self, qdrant_host: str = None, qdrant_port: int = None):
        """Initialize Qdrant client and embedding model."""
        self.qdrant_host = qdrant_host or os.getenv("QDRANT_HOST", "localhost")
        self.qdrant_port = qdrant_port or int(os.getenv("QDRANT_PORT", "6333"))
        
        # Initialize Qdrant client
        self.client = QdrantClient(
            host=self.qdrant_host,
            port=self.qdrant_port,
            timeout=30
        )
        
        # Configure Gemini for embeddings
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("GEMINI_API_KEY environment variable not set")
        genai.configure(api_key=api_key)
        
        logger.info(f"QdrantRAGService initialized: {self.qdrant_host}:{self.qdrant_port}")
    
    def _generate_collection_name(self, session_id: str = None) -> str:
        """Generate unique collection name for this session."""
        if session_id:
            # Hash session_id to ensure valid collection name
            hash_suffix = hashlib.md5(session_id.encode()).hexdigest()[:12]
            return f"{COLLECTION_PREFIX}{hash_suffix}"
        # Default: use timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        return f"{COLLECTION_PREFIX}{timestamp}"
    
    def _parse_products(self, context: str) -> List[Dict[str, Any]]:
        """Parse context string to extract products."""
        import re
        
        try:
            # Try parsing as JSON
            data = json.loads(context)
            
            # Handle different data formats
            if isinstance(data, list):
                return data
            elif isinstance(data, dict):
                # Look for common keys that contain product arrays
                for key in ["products", "items", "data", "results"]:
                    if key in data and isinstance(data[key], list):
                        return data[key]
                # Single product
                return [data]
            
            return []
        except json.JSONDecodeError:
            # Not JSON, try to extract from text
            logger.warning("Context is not pure JSON, attempting text extraction")
            
            products = []
            
            # Try to find JSON objects in text first - use more sophisticated extraction
            # This regex handles nested objects better
            def extract_json_objects(text):
                """Extract all valid JSON objects from text, handling nested braces."""
                objects = []
                i = 0
                while i < len(text):
                    if text[i] == '{':
                        # Found potential JSON start
                        depth = 0
                        start = i
                        in_string = False
                        escape_next = False
                        
                        while i < len(text):
                            char = text[i]
                            
                            if escape_next:
                                escape_next = False
                            elif char == '\\':
                                escape_next = True
                            elif char == '"':
                                in_string = not in_string
                            elif not in_string:
                                if char == '{':
                                    depth += 1
                                elif char == '}':
                                    depth -= 1
                                    if depth == 0:
                                        # Found complete JSON object
                                        json_str = text[start:i+1]
                                        try:
                                            obj = json.loads(json_str)
                                            objects.append(obj)
                                        except:
                                            pass
                                        break
                            i += 1
                    i += 1
                return objects
            
            json_objects = extract_json_objects(context)
            for obj in json_objects:
                if isinstance(obj, dict) and any(k in obj for k in ['name', 'title', 'product_name', 'productName', 'price', 'brand']):
                    products.append(obj)
            
            if products:
                return products
            
            # If no JSON found, treat as plain text - split by sentences or patterns
            logger.info("No JSON found, treating context as plain text chunks")
            
            # Split by common delimiters: sentences ending with period, numbered items, newlines
            # Pattern: "Sáº£n pháº©m 1: ...", "Product 1: ...", or sentences
            lines = re.split(r'(?:\.|\n|\|)', context)
            lines = [l.strip() for l in lines if l.strip() and len(l.strip()) > 5]
            
            # If we have line splits, create pseudo-products from each chunk
            if lines:
                for idx, line in enumerate(lines):
                    products.append({
                        "raw_text": line,
                        "chunk_index": idx + 1,
                        "_is_text_chunk": True
                    })
                logger.info(f"Extracted {len(products)} text chunks from context")
                return products
            
            # Last resort: treat entire context as single item
            if context.strip():
                products.append({
                    "raw_text": context.strip(),
                    "chunk_index": 1,
                    "_is_text_chunk": True
                })
            
            return products
    
    def _product_to_text(self, product: Dict[str, Any], index: int) -> str:
        """Convert a product dict to searchable text."""
        # Handle raw text chunks from non-JSON context
        if product.get("_is_text_chunk"):
            raw = product.get("raw_text", "")
            return f"Ná»™i dung: {raw} | Sá»‘ thá»© tá»±: {index + 1}"
        
        parts = []
        
        # Common product fields with Vietnamese labels for better search
        name = product.get("name") or product.get("title") or product.get("product_name") or product.get("productName", "")
        brand = product.get("brand") or product.get("manufacturer", "")
        price = product.get("price") or product.get("price_usd") or product.get("price_vnd") or product.get("salePrice", "")
        category = product.get("category", "")
        description = product.get("description", "")
        
        if name:
            parts.append(f"TÃªn sáº£n pháº©m: {name}")
        if brand:
            parts.append(f"ThÆ°Æ¡ng hiá»‡u: {brand}")
        if price:
            parts.append(f"GiÃ¡: {price}")
        if category:
            parts.append(f"Danh má»¥c: {category}")
        if description:
            parts.append(f"MÃ´ táº£: {description[:200]}")  # Limit description length
        
        # Add numeric index for counting
        parts.append(f"Sá»‘ thá»© tá»±: {index + 1}")
        
        return " | ".join(parts) if parts else json.dumps(product, ensure_ascii=False)
    
    def _embed_text(self, text: str) -> List[float]:
        """Generate embedding for text using Google's embedding model."""
        try:
            result = genai.embed_content(
                model=EMBEDDING_MODEL,
                content=text,
                task_type="retrieval_document"
            )
            return result['embedding']
        except Exception as e:
            logger.error(f"Embedding failed: {e}")
            raise
    
    def _embed_query(self, query: str) -> List[float]:
        """Generate embedding for query (uses different task_type)."""
        try:
            result = genai.embed_content(
                model=EMBEDDING_MODEL,
                content=query,
                task_type="retrieval_query"
            )
            return result['embedding']
        except Exception as e:
            logger.error(f"Query embedding failed: {e}")
            raise
    
    def _create_collection(self, collection_name: str) -> bool:
        """Create Qdrant collection if not exists."""
        try:
            # Check if collection exists
            collections = self.client.get_collections().collections
            exists = any(c.name == collection_name for c in collections)
            
            if exists:
                # Delete existing collection for fresh data
                self.client.delete_collection(collection_name)
                logger.info(f"Deleted existing collection: {collection_name}")
            
            self.client.create_collection(
                collection_name=collection_name,
                vectors_config=VectorParams(
                    size=EMBEDDING_DIMENSION,
                    distance=Distance.COSINE
                )
            )
            logger.info(f"Created collection: {collection_name}")
            return True
        except Exception as e:
            logger.error(f"Failed to create collection: {e}")
            return False
    
    def _delete_collection(self, collection_name: str) -> bool:
        """Delete Qdrant collection."""
        try:
            self.client.delete_collection(collection_name)
            logger.info(f"Deleted collection: {collection_name}")
            return True
        except Exception as e:
            logger.error(f"Failed to delete collection: {e}")
            return False
    
    async def index_context(self, context: str, session_id: str = None) -> tuple[str, int]:
        """
        Index context data into Qdrant.
        
        Args:
            context: JSON string with products/data
            session_id: Optional session ID for collection naming
            
        Returns:
            Tuple of (collection_name, product_count)
        """
        collection_name = self._generate_collection_name(session_id)
        
        # Create collection
        if not self._create_collection(collection_name):
            raise RuntimeError(f"Failed to create collection {collection_name}")
        
        # Parse products
        products = self._parse_products(context)
        
        if not products:
            logger.warning("No products found in context")
            return collection_name, 0
        
        # Index each product as a point
        logger.info(f"Indexing {len(products)} products into Qdrant")
        points = []
        
        for i, product in enumerate(products):
            text = self._product_to_text(product, i)
            embedding = self._embed_text(text)
            
            point = PointStruct(
                id=i,
                vector=embedding,
                payload={
                    "text": text,
                    "product_data": product,
                    "product_index": i
                }
            )
            points.append(point)
            
            # Log progress every 50 products
            if (i + 1) % 50 == 0:
                logger.info(f"Embedded {i + 1}/{len(products)} products")
        
        # Upsert points in batches
        batch_size = 100
        for i in range(0, len(points), batch_size):
            batch = points[i:i + batch_size]
            self.client.upsert(
                collection_name=collection_name,
                points=batch
            )
        
        logger.info(f"Indexed {len(points)} products to {collection_name}")
        return collection_name, len(points)
    
    async def search(self, collection_name: str, query: str, top_k: int = TOP_K_RESULTS) -> List[Dict[str, Any]]:
        """
        Search Qdrant collection for relevant products.
        
        Args:
            collection_name: Qdrant collection name
            query: User's question
            top_k: Number of results to return
            
        Returns:
            List of relevant products with scores
        """
        import requests as http_requests
        
        try:
            query_embedding = self._embed_query(query)
            
            # Use REST API directly for compatibility with Qdrant 1.7.x
            # POST /collections/{collection_name}/points/search
            search_url = f"http://{self.qdrant_host}:{self.qdrant_port}/collections/{collection_name}/points/search"
            
            search_body = {
                "vector": query_embedding,
                "limit": top_k,
                "with_payload": True
            }
            
            response = http_requests.post(search_url, json=search_body)
            
            if response.status_code != 200:
                logger.error(f"Search API error: {response.status_code} - {response.text}")
                return []
            
            data = response.json()
            results_list = data.get("result", [])
            
            products = []
            for hit in results_list:
                payload = hit.get("payload", {})
                products.append({
                    "text": payload.get("text", ""),
                    "score": hit.get("score", 0),
                    "product_data": payload.get("product_data"),
                    "product_index": payload.get("product_index", -1)
                })
            
            logger.info(f"Found {len(products)} relevant products for query")
            return products
            
        except Exception as e:
            logger.error(f"Search failed: {e}")
            return []
    
    async def answer_with_rag(
        self, 
        context: str, 
        query: str, 
        session_id: str = None,
        gemini_model = None,
        gemini_client = None
    ) -> str:
        """
        Full RAG pipeline: index â†’ search â†’ generate answer.
        
        Args:
            context: JSON string with products/data
            query: User's question
            session_id: Optional session ID
            gemini_model: Gemini model for text generation (legacy, deprecated)
            gemini_client: GeminiClient instance (preferred - supports multiple providers)
            
        Returns:
            Natural language answer
        """
        try:
            # Step 1: Index context data
            collection_name, product_count = await self.index_context(context, session_id)
            
            if product_count == 0:
                return "KhÃ´ng tÃ¬m tháº¥y sáº£n pháº©m nÃ o trong dá»¯ liá»‡u Ä‘Ã£ crawl."
            
            # Step 2: Search for relevant products (get ALL indexed products for listing queries)
            # Use product_count as top_k to ensure we retrieve all items
            search_limit = min(product_count, TOP_K_RESULTS)  # Use actual count or max limit
            relevant_products = await self.search(collection_name, query, top_k=search_limit)
            
            if not relevant_products:
                return "KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan trong dá»¯ liá»‡u Ä‘Ã£ crawl."
            
            # Step 3: Build context from relevant products
            rag_context_parts = []
            rag_context_parts.append(f"Tá»”NG Sá» Sáº¢N PHáº¨M ÄÃƒ CRAWL: {product_count}")
            rag_context_parts.append("")
            rag_context_parts.append("Sáº¢N PHáº¨M LIÃŠN QUAN (tá»« semantic search):")
            
            # Pre-count brands for accurate visualization
            import re
            brand_counts = {}
            products_without_brand = []
            
            for i, product in enumerate(relevant_products):
                rag_context_parts.append(f"\n[Sáº£n pháº©m {i+1}, Äá»™ liÃªn quan: {product['score']:.2f}]")
                rag_context_parts.append(product['text'])
                
                brand_found = False
                brand = None
                
                # Try to get brand from product_data first
                if product['product_data']:
                    rag_context_parts.append(f"Raw data: {json.dumps(product['product_data'], ensure_ascii=False)}")
                    
                    pdata = product['product_data']
                    if isinstance(pdata, dict):
                        brand = pdata.get('brand') or pdata.get('Brand') or pdata.get('thuong_hieu') or pdata.get('ThÆ°Æ¡ng hiá»‡u')
                    
                    if brand and isinstance(brand, str) and brand.strip():
                        brand = brand.strip()
                        brand_counts[brand] = brand_counts.get(brand, 0) + 1
                        brand_found = True
                
                # If no brand from product_data, try regex on text
                if not brand_found and product['text']:
                    text = product['text']
                    # Try multiple patterns to extract brand (both with and without Vietnamese diacritics)
                    patterns = [
                        r'ThÆ°Æ¡ng hiá»‡u[:\s]+([^\n\|,]+)',  # "ThÆ°Æ¡ng hiá»‡u: XXX" (with diacritics)
                        r'Thuong hieu[:\s]+([^\n\|,]+)',  # "Thuong hieu: XXX" (without diacritics)
                        r'\|\s*ThÆ°Æ¡ng hiá»‡u[:\s]*([^\n\|]+)\s*\|',  # "| ThÆ°Æ¡ng hiá»‡u: XXX |"
                        r'\|\s*Thuong hieu[:\s]*([^\n\|]+)\s*\|',  # "| Thuong hieu: XXX |"
                        r'Brand[:\s]+([^\n\|,]+)',  # "Brand: XXX"
                        r'NhÃ£n hiá»‡u[:\s]+([^\n\|,]+)',  # "NhÃ£n hiá»‡u: XXX"
                        r'Nhan hieu[:\s]+([^\n\|,]+)',  # "Nhan hieu: XXX"
                    ]
                    
                    for pattern in patterns:
                        brand_match = re.search(pattern, text, re.IGNORECASE)
                        if brand_match:
                            brand = brand_match.group(1).strip()
                            if brand:
                                brand_counts[brand] = brand_counts.get(brand, 0) + 1
                                brand_found = True
                                break
                
                if not brand_found:
                    products_without_brand.append(i + 1)
            
            # Log for debugging
            logger.info(f"ðŸ“Š Brand counting: {len(relevant_products)} products processed")
            logger.info(f"ðŸ“Š Brands found: {len(brand_counts)} unique brands")
            logger.info(f"ðŸ“Š Brand counts: {brand_counts}")
            logger.info(f"ðŸ“Š Total counted: {sum(brand_counts.values())}")
            if products_without_brand:
                logger.warning(f"ðŸ“Š Products without brand: {products_without_brand[:10]}...")  # Show first 10
            
            rag_context = "\n".join(rag_context_parts)
            
            # Step 4: Generate answer with Gemini
            
            # Detect visualization request
            viz_keywords = ['váº½ biá»ƒu Ä‘á»“', 've bieu do', 'chart', 'graph', 'visualization', 'visualize', 'táº¡o biá»ƒu Ä‘á»“', 'tao bieu do']
            is_viz_request = any(keyword in query.lower() for keyword in viz_keywords)
            
            if is_viz_request:
                # Detect chart type from query
                query_lower = query.lower()
                if any(kw in query_lower for kw in ['trÃ²n', 'pie', 'donut', 'doughnut']):
                    suggested_chart_type = "pie"
                elif any(kw in query_lower for kw in ['Ä‘Æ°á»ng', 'line', 'trend']):
                    suggested_chart_type = "line"
                else:
                    suggested_chart_type = "bar"
                
                # Check if query is about brands/thÆ°Æ¡ng hiá»‡u and we have pre-counted data
                is_brand_query = any(kw in query_lower for kw in ['thÆ°Æ¡ng hiá»‡u', 'thuong hieu', 'brand', 'nhÃ£n hiá»‡u', 'nhan hieu'])
                
                if is_brand_query and brand_counts:
                    # Sort by count descending
                    sorted_brands = sorted(brand_counts.items(), key=lambda x: x[1], reverse=True)
                    labels = [b[0] for b in sorted_brands]
                    data = [b[1] for b in sorted_brands]
                    total_counted = sum(data)
                    
                    # Generate chart JSON directly from pre-counted data
                    chart_json = {
                        "chart_type": suggested_chart_type,
                        "data": data,
                        "labels": labels
                    }
                    
                    logger.info(f"ðŸ“Š Pre-counted brand data: {len(brand_counts)} brands, {total_counted} products")
                    logger.info(f"ðŸ“Š Brand counts: {brand_counts}")
                    
                    # Build response with pre-counted accurate data
                    prompt = f"""Báº¡n lÃ  trá»£ lÃ½ AI. Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c Ä‘áº¿m chÃ­nh xÃ¡c báº±ng code:

**Tá»”NG Sá» Sáº¢N PHáº¨M:** {product_count}
**Sá» THÆ¯Æ NG HIá»†U:** {len(brand_counts)}

**THá»NG KÃŠ CHÃNH XÃC THEO THÆ¯Æ NG HIá»†U (Ä‘Ã£ Ä‘áº¿m báº±ng code):**
{json.dumps(brand_counts, ensure_ascii=False, indent=2)}

CÃ‚U Há»ŽI: {query}

**Báº®T BUá»˜C:** Tráº£ vá» summary ngáº¯n gá»n + JSON chÃ­nh xÃ¡c sau:

{json.dumps(chart_json, ensure_ascii=False)}

VÃ­ dá»¥ output:
Dá»±a trÃªn {total_counted} sáº£n pháº©m tá»« {len(brand_counts)} thÆ°Æ¡ng hiá»‡u, phÃ¢n bá»‘ nhÆ° sau:

{json.dumps(chart_json, ensure_ascii=False)}"""
                else:
                    # Fallback: Let LLM analyze (less accurate)
                    prompt = f"""Báº¡n lÃ  trá»£ lÃ½ AI chuyÃªn phÃ¢n tÃ­ch vÃ  visualize dá»¯ liá»‡u sáº£n pháº©m.

{rag_context}

CÃ‚U Há»ŽI: {query}

**Báº®T BUá»˜C: Tráº£ vá» JSON vá»›i Ä‘á»‹nh dáº¡ng:**

```json
{{
  "chart_type": "{suggested_chart_type}",
  "data": [sá»‘1, sá»‘2, sá»‘3, ...],
  "labels": ["label1", "label2", "label3", ...]
}}
```

**HÆ¯á»šNG DáºªN:**
1. Äáº¿m CHÃNH XÃC tá»«ng sáº£n pháº©m theo tiÃªu chÃ­ Ä‘Æ°á»£c yÃªu cáº§u
2. KHÃ”NG Ä‘Æ°á»£c Æ°á»›c lÆ°á»£ng - pháº£i Ä‘áº¿m tá»«ng item má»™t
3. Kiá»ƒm tra láº¡i tá»•ng = {product_count}
4. **Báº®T BUá»˜C** return JSON vá»›i chart_type, data, labels

**Báº®T BUá»˜C: JSON pháº£i cÃ³ Ä‘á»§ 3 fields: chart_type, data, labels. KHÃ”NG cÃ³ comments trong JSON.**"""
            else:
                # Normal prompt for non-visualization queries
                # Detect if this is a listing request
                list_keywords = ['liá»‡t kÃª', 'liet ke', 'list', 'danh sÃ¡ch', 'danh sach', 'táº¥t cáº£', 'tat ca', 'all', 'toÃ n bá»™', 'toan bo', 'Ä‘áº§y Ä‘á»§', 'day du', 'full']
                is_listing_request = any(keyword in query.lower() for keyword in list_keywords)
                
                if is_listing_request:
                    prompt = f"""Báº¡n lÃ  trá»£ lÃ½ AI chuyÃªn phÃ¢n tÃ­ch dá»¯ liá»‡u sáº£n pháº©m Ä‘Ã£ Ä‘Æ°á»£c crawl.

**Dá»® LIá»†U Sáº¢N PHáº¨M:**
{rag_context}

**CÃ‚U Há»ŽI:** {query}

**CHá»ˆ THá»Š Báº®T BUá»˜C:**
1. LIá»†T KÃŠ Táº¤T Cáº¢ {product_count} Sáº¢N PHáº¨M NGAY Láº¬P Tá»¨C
2. KHÃ”NG ÄÆ¯á»¢C há»i xÃ¡c nháº­n, khÃ´ng Ä‘Æ°á»£c viáº¿t "HÃ£y xÃ¡c nháº­n", "cÃ³ muá»‘n xem tiáº¿p khÃ´ng"
3. KHÃ”NG ÄÆ¯á»¢C viáº¿t "Do Ä‘á»™ dÃ i...", "QuÃ¡ dÃ i...", "Tiáº¿p tá»¥c náº¿u..."
4. KHÃ”NG ÄÆ¯á»¢C dá»«ng giá»¯a chá»«ng - PHáº¢I liá»‡t kÃª tá»« sáº£n pháº©m #1 Ä‘áº¿n #{product_count}
5. Format: **[Sá»‘ thá»© tá»±]. [TÃªn sáº£n pháº©m]** | ThÆ°Æ¡ng hiá»‡u: [Brand] | GiÃ¡: [Price]â‚«
6. Báº®T Äáº¦U NGAY vá»›i sáº£n pháº©m #1, Káº¾T THÃšC vá»›i sáº£n pháº©m #{product_count}

**Báº®T Äáº¦U LIá»†T KÃŠ:**
"""
                else:
                    prompt = f"""Báº¡n lÃ  trá»£ lÃ½ AI chuyÃªn phÃ¢n tÃ­ch dá»¯ liá»‡u sáº£n pháº©m Ä‘Ã£ Ä‘Æ°á»£c crawl.
HÃ£y tráº£ lá»i cÃ¢u há»i dá»±a trÃªn dá»¯ liá»‡u Ä‘Æ°á»£c cung cáº¥p.

{rag_context}

CÃ‚U Há»ŽI: {query}

HÆ¯á»šNG DáºªN:
1. PhÃ¢n tÃ­ch ká»¹ dá»¯ liá»‡u Ä‘á»ƒ tÃ¬m cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c
2. Náº¿u cÃ¢u há»i yÃªu cáº§u TÃNH TOÃN (Ä‘áº¿m sá»‘ lÆ°á»£ng, tÃ­nh trung bÃ¬nh, tá»•ng, max, min):
   - Sá»¬ Dá»¤NG "Tá»”NG Sá» Sáº¢N PHáº¨M ÄÃƒ CRAWL" cho cÃ¢u há»i Ä‘áº¿m tá»•ng
   - Thá»±c hiá»‡n phÃ©p tÃ­nh dá»±a trÃªn dá»¯ liá»‡u sáº£n pháº©m
   - ÄÆ°a ra káº¿t quáº£ sá»‘ cá»¥ thá»ƒ
3. Náº¿u khÃ´ng tÃ¬m tháº¥y thÃ´ng tin, hÃ£y nÃ³i rÃµ
4. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, chÃ­nh xÃ¡c vÃ  chi tiáº¿t

CÃ‚U TRáº¢ Lá»œI:"""

            # Step 4: Generate answer using available LLM
            # Priority: gemini_client (multi-provider) > gemini_model (legacy) > direct Gemini
            if gemini_client:
                # Use GeminiClient which supports multiple providers via adapter
                logger.info("Generating answer via GeminiClient (multi-provider)")
                answer = await gemini_client.generate(prompt)
                
                # DEBUG: Log answer length and preview for visualization queries
                if is_viz_request:
                    logger.info(f"ðŸ“Š Visualization answer length: {len(answer)} chars")
                    logger.info(f"ðŸ“Š Answer preview (first 500 chars): {answer[:500]}")
                    logger.info(f"ðŸ“Š Answer preview (last 200 chars): {answer[-200:]}")
                    
            elif gemini_model:
                import asyncio
                response = await asyncio.to_thread(
                    gemini_model.generate_content, prompt
                )
                answer = response.text if hasattr(response, 'text') else str(response)
            else:
                # Fallback to direct Gemini call
                model = genai.GenerativeModel("models/gemini-2.0-flash")
                response = model.generate_content(prompt)
                answer = response.text if hasattr(response, 'text') else str(response)
            
            # Step 5: Cleanup collection
            self._delete_collection(collection_name)
            
            return answer
            
        except Exception as e:
            logger.error(f"RAG pipeline failed: {e}", exc_info=True)
            return f"Lá»—i khi xá»­ lÃ½ cÃ¢u há»i: {str(e)}"
    
    def cleanup_old_collections(self, max_age_hours: int = 24) -> int:
        """
        Cleanup old collections to free up space.
        
        Args:
            max_age_hours: Delete collections older than this
            
        Returns:
            Number of collections deleted
        """
        try:
            collections = self.client.get_collections().collections
            deleted = 0
            
            for collection in collections:
                if collection.name.startswith(COLLECTION_PREFIX):
                    # Extract timestamp if present
                    try:
                        parts = collection.name.replace(COLLECTION_PREFIX, "").split("_")
                        if len(parts) >= 3:
                            date_str = f"{parts[0]}_{parts[1]}"
                            created_at = datetime.strptime(date_str, "%Y%m%d_%H%M%S")
                            age = datetime.now() - created_at
                            
                            if age > timedelta(hours=max_age_hours):
                                self._delete_collection(collection.name)
                                deleted += 1
                    except (ValueError, IndexError):
                        # Can't parse date, skip
                        pass
            
            logger.info(f"Cleanup: deleted {deleted} old collections")
            return deleted
            
        except Exception as e:
            logger.error(f"Cleanup failed: {e}")
            return 0


# Singleton instance
_rag_service: Optional[QdrantRAGService] = None

def get_rag_service() -> Optional[QdrantRAGService]:
    """Get or create RAG service singleton."""
    global _rag_service
    if _rag_service is None:
        try:
            _rag_service = QdrantRAGService()
        except Exception as e:
            logger.warning(f"Failed to initialize Qdrant RAG service: {e}")
            return None
    return _rag_service
