# ============================================================================
# Self-Learning Agent Configuration
# Copy this file to .env.self-learning and fill in your values
# ============================================================================

# ============================================================================
# API KEYS
# ============================================================================

# Gemini API Key (Required)
GEMINI_API_KEY=your-gemini-api-key-here

# ============================================================================
# DATABASE PASSWORDS
# ============================================================================

# PostgreSQL
POSTGRES_PASSWORD=your-secure-password-here

# Neo4j Graph Database
NEO4J_PASSWORD=your-neo4j-password-here

# ============================================================================
# OPTIONAL: LOCAL LLM
# ============================================================================

# Enable local LLM for cost savings (requires GPU)
LOCAL_LLM_ENABLED=false
LOCAL_LLM_ENDPOINT=http://ollama:11434

# ============================================================================
# OPTIONAL: MONITORING
# ============================================================================

# Grafana admin password
GRAFANA_PASSWORD=admin

# ============================================================================
# TRAINING CONFIGURATION
# ============================================================================

# Update frequency (every N rollouts)
UPDATE_FREQUENCY=5

# Maximum rollouts per session
MAX_ROLLOUTS_PER_SESSION=100

# Parallel runners
PARALLEL_RUNNERS=4

# ============================================================================
# KNOWLEDGE STORE LIMITS (Auto-adjusted by RL Controller)
# ============================================================================

# Initial max size in GB
INITIAL_KNOWLEDGE_STORE_MAX_SIZE_GB=2.0

# Initial retention in days
INITIAL_PATTERN_RETENTION_DAYS=30

# Minimum pattern frequency to keep
INITIAL_MIN_PATTERN_FREQUENCY=3

# Persistent feedback log
FEEDBACK_STORE_PATH=knowledge_db/feedback_history.jsonl

# ============================================================================
# GEMINI OPTIMIZATION
# ============================================================================

# Cache TTL in seconds
CACHE_TTL_SECONDS=3600

# Max batch size for requests
MAX_BATCH_SIZE=8

# Batch timeout in seconds
BATCH_TIMEOUT_SECONDS=1.0

# Local LLM threshold (characters)
LOCAL_LLM_THRESHOLD_CHARS=5000

# ============================================================================
# SERVICE PORTS
# ============================================================================

PRODUCTION_SERVICE_PORT=5014
TRAINING_SERVICE_PORT=5020
TRAINING_UI_PORT=3001

# ============================================================================
# INFRASTRUCTURE PORTS
# ============================================================================

QDRANT_PORT=6333
NEO4J_HTTP_PORT=7474
NEO4J_BOLT_PORT=7687
REDIS_PORT=6379
POSTGRES_PORT=5432
OLLAMA_PORT=11434

# ============================================================================
# NOTES
# ============================================================================

# 1. Generate strong passwords for production
# 2. LOCAL_LLM_ENABLED requires GPU support
# 3. Start with monitoring: docker-compose --profile with-monitoring up
# 4. Start with local LLM: docker-compose --profile with-local-llm up
# 5. Both: docker-compose --profile with-monitoring --profile with-local-llm up
